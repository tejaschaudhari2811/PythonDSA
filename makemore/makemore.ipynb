{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "words = open(\"./names.txt\",\"r\").read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(words)))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi.update({\".\":0})\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.zeros((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams \n",
    "for word in words:\n",
    "    word = \".\" + word + \".\"\n",
    "    for ch, ch2 in zip(word, word[1:]):\n",
    "        ix1, ix2 = stoi[ch], stoi[ch2]\n",
    "        P[ix1, ix2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolian.\n",
      "juee.\n",
      "ksahnaauranilevias.\n",
      "dedainrwieta.\n",
      "ssonielylarte.\n",
      "faveumerifontume.\n",
      "phynslenaruani.\n",
      "core.\n",
      "yaenon.\n",
      "ka.\n",
      "jabdinerimikimaynin.\n",
      "anaasn.\n",
      "ssorionsush.\n"
     ]
    }
   ],
   "source": [
    "g=torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    index = 0\n",
    "    while True:\n",
    "        p = P[index].float()\n",
    "        p /= p.sum()\n",
    "        index = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        print(itos[index], end=\"\")\n",
    "        if index == 0:\n",
    "            print(\"\")\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "xs = f.one_hot(torch.tensor([0,5,13,13,1]), num_classes=27).float()\n",
    "ys = torch.tensor([5,13,13,1,0]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [],[]\n",
    "for word in words:\n",
    "    word = [\".\"]+ list(word) + [\".\"]\n",
    "    for ch, ch2 in zip(word, word[1:]):\n",
    "        xs.append(stoi[ch]), ys.append(stoi[ch2])\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xenc = f.one_hot(xs, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27), generator=g, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 27])\n",
      "torch.Size([27, 27])\n"
     ]
    }
   ],
   "source": [
    "# Check how much each neuron fires for each input\n",
    "print(xenc.shape)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.717190980911255\n",
      "3.33760404586792\n",
      "3.1265954971313477\n",
      "2.9947545528411865\n",
      "2.9025564193725586\n",
      "2.8342947959899902\n",
      "2.782829761505127\n",
      "2.7433440685272217\n",
      "2.7124502658843994\n",
      "2.687736749649048\n",
      "2.6675140857696533\n",
      "2.6506080627441406\n",
      "2.6362011432647705\n",
      "2.6237223148345947\n",
      "2.6127710342407227\n",
      "2.603057861328125\n",
      "2.5943713188171387\n",
      "2.5865490436553955\n",
      "2.579464912414551\n",
      "2.5730185508728027\n",
      "2.5671274662017822\n",
      "2.5617241859436035\n",
      "2.556751012802124\n",
      "2.5521600246429443\n",
      "2.547910213470459\n",
      "2.543966054916382\n",
      "2.540296792984009\n",
      "2.5368759632110596\n",
      "2.5336806774139404\n",
      "2.5306906700134277\n",
      "2.5278875827789307\n",
      "2.5252559185028076\n",
      "2.52278208732605\n",
      "2.5204529762268066\n",
      "2.518256902694702\n",
      "2.5161843299865723\n",
      "2.5142264366149902\n",
      "2.512373685836792\n",
      "2.510619878768921\n",
      "2.5089569091796875\n",
      "2.5073788166046143\n",
      "2.505880117416382\n",
      "2.5044548511505127\n",
      "2.503098726272583\n",
      "2.5018064975738525\n",
      "2.500574827194214\n",
      "2.499398946762085\n",
      "2.4982762336730957\n",
      "2.4972023963928223\n",
      "2.4961750507354736\n",
      "2.4951915740966797\n",
      "2.4942493438720703\n",
      "2.493344783782959\n",
      "2.4924774169921875\n",
      "2.4916436672210693\n",
      "2.490842580795288\n",
      "2.490072250366211\n",
      "2.489330291748047\n",
      "2.488616466522217\n",
      "2.4879279136657715\n",
      "2.4872641563415527\n",
      "2.486624002456665\n",
      "2.4860057830810547\n",
      "2.4854085445404053\n",
      "2.4848315715789795\n",
      "2.484273672103882\n",
      "2.483733892440796\n",
      "2.4832115173339844\n",
      "2.4827053546905518\n",
      "2.482215404510498\n",
      "2.4817397594451904\n",
      "2.4812793731689453\n",
      "2.480832099914551\n",
      "2.480398416519165\n",
      "2.4799771308898926\n",
      "2.4795680046081543\n",
      "2.479170799255371\n",
      "2.4787838459014893\n",
      "2.4784085750579834\n",
      "2.4780426025390625\n",
      "2.477686882019043\n",
      "2.4773406982421875\n",
      "2.477003574371338\n",
      "2.476675033569336\n",
      "2.4763545989990234\n",
      "2.4760427474975586\n",
      "2.475738763809204\n",
      "2.4754416942596436\n",
      "2.4751522541046143\n",
      "2.474869728088379\n",
      "2.4745941162109375\n",
      "2.474324941635132\n",
      "2.474062204360962\n",
      "2.4738051891326904\n",
      "2.4735541343688965\n",
      "2.473309278488159\n",
      "2.473069429397583\n",
      "2.472834825515747\n",
      "2.4726061820983887\n",
      "2.472381830215454\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):    \n",
    "    logits = xenc @ W\n",
    "    exp_act = torch.exp(logits)\n",
    "    probs = exp_act / exp_act.sum(1, keepdim = True)\n",
    "    loss = -probs[torch.arange(xs.nelement()), ys].log().mean()\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -50*W.grad\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.\n",
      "pfda.\n",
      "rilisindden.\n",
      "cay.\n",
      "judaliaynytah.\n",
      "ldiminaycyalyvialalee.\n",
      "ubeiah.\n",
      "milziseoll.\n",
      "and.\n",
      "m.\n"
     ]
    }
   ],
   "source": [
    "# predicting with the neural network\n",
    "\n",
    "for _ in range(10):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "        p = f.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = p @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts/counts.sum(1, keepdim = True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
